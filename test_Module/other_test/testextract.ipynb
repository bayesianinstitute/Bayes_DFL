{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used RAM: 12.54 GB\n",
      "Total RAM: 15.24 GB\n",
      "Available RAM: 2.70 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Get RAM usage\n",
    "ram = psutil.virtual_memory()\n",
    "used_ram = ram.used\n",
    "total_ram = ram.total\n",
    "\n",
    "# Get available RAM\n",
    "available_ram = ram.available\n",
    "\n",
    "print(f\"Used RAM: {used_ram / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Total RAM: {total_ram / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Available RAM: {available_ram / (1024 ** 3):.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QmSYSi2nnYCvAN6wCQ88oQ7ojm7xrBy6DjmnKJL2Rty8DF', 'QmNe3kkMMUuGHNb9dovtupAztvBqmVfQoHpp9C6yria46Q', 'QmPiRbnfHxne4opfJtPmBcP98r3vUi3R7RptnjvTVomqNC', 'QmcCeHq8GGe8r3Qtoi8C2FJhVeWuRqfUYjK7x6pxRP3AwF', 'QmdiCS8L5TGdYrvZioneSSi4zPJeQhaV37HKp7pCGiEXq9']\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'USA_Client_1': 'QmSYSi2nnYCvAN6wCQ88oQ7ojm7xrBy6DjmnKJL2Rty8DF',\n",
    "    'USA_Client_2': 'QmNe3kkMMUuGHNb9dovtupAztvBqmVfQoHpp9C6yria46Q',\n",
    "    'USA_Client_3': 'QmPiRbnfHxne4opfJtPmBcP98r3vUi3R7RptnjvTVomqNC',\n",
    "    'USA_Client_4': 'QmcCeHq8GGe8r3Qtoi8C2FJhVeWuRqfUYjK7x6pxRP3AwF',\n",
    "    'USA_Client_5': 'QmdiCS8L5TGdYrvZioneSSi4zPJeQhaV37HKp7pCGiEXq9'\n",
    "}\n",
    "\n",
    "# Extract all hashes\n",
    "hashes = list(data.values())\n",
    "\n",
    "# Print the list of hashes\n",
    "print(hashes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QmRdj9MiRduK4NDoDpEtGZmJBm3Bb8F85vbT5FLS5VmY7q', 'QmRLEfaJTrhmhSAiuawz56k18iUxj1tsLzmLMpbwTiR6jU', 'QmR3gbdGdVPAabxbXU9gtA8JtiSnne98NACX4uxg3mxD1g']\n"
     ]
    }
   ],
   "source": [
    "client_hash_mapping ={'USA_Client_1': 'QmRdj9MiRduK4NDoDpEtGZmJBm3Bb8F85vbT5FLS5VmY7q', 'USA_Client_2': 'QmRLEfaJTrhmhSAiuawz56k18iUxj1tsLzmLMpbwTiR6jU', 'USA_Client_3': 'QmR3gbdGdVPAabxbXU9gtA8JtiSnne98NACX4uxg3mxD1g'} \n",
    "\n",
    "# Extract all hashes\n",
    "hashes = list(client_hash_mapping.values())\n",
    "\n",
    "# Print the list of hashes\n",
    "print(hashes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value for key key1 is ther\n",
      "The value for key key2 is None\n",
      "The value for key key3 is ther\n",
      "The value for key key4 is None\n"
     ]
    }
   ],
   "source": [
    "my_dict = {'key1': 42, 'key2': None, 'key3': 'Hello', 'key4': None}\n",
    "i=1\n",
    "while True:\n",
    "    i=i+1\n",
    "    for key, value in my_dict.items():\n",
    "        if value is None:\n",
    "            print(f'The value for key {key} is None')\n",
    "        else :\n",
    "            print(f'The value for key {key} is ther')\n",
    "    my_dict['key2']=3\n",
    "    if i==3:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2579 - accuracy: 0.9271\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1153 - accuracy: 0.9657\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0798 - accuracy: 0.9754\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0595 - accuracy: 0.9814\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0462 - accuracy: 0.9857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x24045cfcb10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Build a simple neural network model\n",
    "model = keras.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),  # Flatten the 28x28 images to 1D array\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 712us/step\n",
      "First prediction: [1.2759973e-08 2.3459906e-07 1.1225570e-05 1.0095039e-04 1.2984784e-09\n",
      " 1.4441661e-08 9.8060943e-12 9.9986804e-01 1.4150429e-06 1.8075274e-05]\n",
      "The weights for this layer are approximately the same within the tolerance.\n",
      "The weights for this layer are approximately the same within the tolerance.\n",
      "The weights for this layer are approximately the same within the tolerance.\n",
      "The weights for this layer are approximately the same within the tolerance.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Build a simple neural network model\n",
    "model = keras.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),  # Flatten the 28x28 images to 1D array\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "\n",
    "\n",
    "# Save the model\n",
    "model.save('mnist_model.keras')\n",
    "\n",
    "# Load the model from the file\n",
    "loaded_model = keras.models.load_model('mnist_model.keras')\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "predictions = loaded_model.predict(test_images)\n",
    "\n",
    "# Print the first prediction\n",
    "print(\"First prediction:\", predictions[0])\n",
    "\n",
    "prev_weights = model.get_weights()\n",
    "new_weights = loaded_model.get_weights()\n",
    "\n",
    "# Check if the weights are approximately the same within the tolerance for each layer\n",
    "for layer_prev, layer_new in zip(prev_weights, new_weights):\n",
    "    if np.allclose(layer_prev, layer_new, rtol=1e-5, atol=1e-5):\n",
    "        print(\"The weights for this layer are approximately the same within the tolerance.\")\n",
    "    else:\n",
    "        print(\"The weights for this layer are not exactly the same.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
